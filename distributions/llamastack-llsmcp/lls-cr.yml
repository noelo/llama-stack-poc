apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llsphi-4
spec:
  replicas: 1
  server:
    containerSpec:
      env:
        - name: VLLM_TLS_VERIFY
          value: 'false'
        - name: VLLM_MAX_TOKENS
          value: '6000'
        - name: LLAMA_STACK_CLIENT_LOG
          value: debug 
        - name: INFERENCE_MODEL
          value: 'microsoft/phi-4'
        - name: VLLM_DEBUG_LOG_API_SERVER_RESPONSE
          value: 'true' 
        - name: VLLM_URL
          value: https://phi-4-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com:443/v1
        - name: VLLM_API_TOKEN
          value: e5a33eb9617653178addd0ab1f50a57e
        - name: MILVUS_DB_PATH
          value: /home/lls/.lls/milvus.db
      name: llama-stack
    distribution:
      image: quay.io/noeloc/llsmcp:latest
      size: "20Gi"
      mountPath: "/home/lls/.lls"  # Optional, defaults to /.llama. Use with custom distribution images that have a different setup.
    userConfig:
      configMapName: llsmcp